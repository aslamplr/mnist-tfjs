{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Model_for_web.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wwA8UssSmJuE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST Handwritten digit classifier in browser\n",
        "\n",
        "This notebook creates, train and export a model trained in MNIST handwritten digit classifying task, to be imported by tfjs in browser.\n"
      ]
    },
    {
      "metadata": {
        "id": "BsJ7LGe-mmoS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "install `tensorflowjs`, which is only required in this notebook for saving the model compatible with `tensorflowjs`"
      ]
    },
    {
      "metadata": {
        "id": "855JDkg9jBMa",
        "colab_type": "code",
        "outputId": "5dca2cdf-9350-43fa-80a4-5bd8b4a78c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1211
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/79/29/35e1aa467436ff46b98df65a08c49faaedb3429e1c512d1d90fe308040a0/tensorflowjs-1.0.1-py3-none-any.whl\n",
            "Collecting tf-nightly-2.0-preview>=2.0.0.dev20190304 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/02/e7ac2983803c11d7a0be5747cb8ba5ac7992e21ec21faa41f345c6925ab8/tf_nightly_2.0_preview-2.0.0.dev20190426-cp36-cp36m-manylinux1_x86_64.whl (86.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 86.2MB 436kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 3.2MB/s \n",
            "\u001b[?25hCollecting six==1.11.0 (from tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
            "Collecting tensorflow-hub==0.3.0 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/f0/3a3ced04c8359e562f1b91918d9bde797c8a916fcfeddc8dc5d673d1be20/tensorflow_hub-0.3.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 31.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.4)\n",
            "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/bd/4c0c1fd31e8d7a6db4b13c7ec3dc7293c4319b134168951a9c9d3f715450/tb_nightly-1.14.0a20190426-py3-none-any.whl (3.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 32.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.7)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/47/1a7a31baa3e34b33bc241014a6295588019e2922e3546a891e65f7671b8d/tensorflow_estimator_2.0_preview-1.14.0.dev2019042600-py2.py3-none-any.whl (421kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 22.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.33.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.9)\n",
            "Collecting wrapt>=1.11.1 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (40.9.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
            "Successfully built wrapt\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31ms3fs 0.2.1 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, numpy, tb-nightly, google-pasta, tensorflow-estimator-2.0-preview, wrapt, tf-nightly-2.0-preview, tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: numpy 1.16.3\n",
            "    Uninstalling numpy-1.16.3:\n",
            "      Successfully uninstalled numpy-1.16.3\n",
            "  Found existing installation: wrapt 1.10.11\n",
            "    Uninstalling wrapt-1.10.11:\n",
            "      Successfully uninstalled wrapt-1.10.11\n",
            "  Found existing installation: tensorflow-hub 0.4.0\n",
            "    Uninstalling tensorflow-hub-0.4.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.4.0\n",
            "Successfully installed google-pasta-0.1.5 numpy-1.15.1 six-1.11.0 tb-nightly-1.14.0a20190426 tensorflow-estimator-2.0-preview-1.14.0.dev2019042600 tensorflow-hub-0.3.0 tensorflowjs-1.0.1 tf-nightly-2.0-preview-2.0.0.dev20190426 wrapt-1.11.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rjf9ZYItm2Yx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Packages required for the notebook"
      ]
    },
    {
      "metadata": {
        "id": "twu1gnJ0h8_G",
        "colab_type": "code",
        "outputId": "907c5974-0521-4904-db42-bb665b1abf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "from tensorflow import keras\n",
        "\n",
        "print('tensorflow', tf.__version__)\n",
        "print('tensorflowjs', tfjs.__version__)\n",
        "print('keras', keras.__version__)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow 2.0.0-dev20190426\n",
            "tensorflowjs 1.0.1\n",
            "keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aZeVYmBiMEn0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While this notebook was written the versions used were - \n",
        "```\n",
        "tensorflow 2.0.0-dev20190412\n",
        "tensorflowjs 1.0.1\n",
        "keras 2.2.4-tf\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "ZeTyjXn0ny-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Constants"
      ]
    },
    {
      "metadata": {
        "id": "DkSnKIQNnyVj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_WIDTH = 28\n",
        "IMAGE_HEIGHT = 28\n",
        "IMAGE_CHANNELS = 1\n",
        "\n",
        "NUM_EPOCHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15udzoCYnMDd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The model\n",
        "\n",
        "Let's create the model"
      ]
    },
    {
      "metadata": {
        "id": "ktSJlZx2nh4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    model = keras.Sequential()\n",
        "    \n",
        "    # In the first layer of out convolutional neural network we have\n",
        "    # to specify the input shape. Then we specify some paramaters for\n",
        "    # the convolution operation that takes place in this layer.\n",
        "    model.add(keras.layers.Conv2D(\n",
        "        input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
        "        kernel_size=5,\n",
        "        filters=16,\n",
        "        strides=1,\n",
        "        activation='relu',\n",
        "        kernel_initializer='VarianceScaling',\n",
        "        kernel_regularizer=keras.regularizers.l2(0.001)\n",
        "    ))\n",
        "    \n",
        "    # The MaxPooling layer acts as a sort of downsampling using max values\n",
        "    # in a region instead of averaging.\n",
        "    model.add(keras.layers.MaxPool2D(\n",
        "        pool_size=(2,2), \n",
        "        strides=(2,2)\n",
        "    ))\n",
        "    \n",
        "    model.add(keras.layers.Dropout(0.05))\n",
        "    \n",
        "    # Repeat another Conv2D + MazPooling stack.\n",
        "    # Note that we have more filters in the convolution.\n",
        "    model.add(keras.layers.Conv2D(\n",
        "        kernel_size=5,\n",
        "        filters=8,\n",
        "        strides=1,\n",
        "        activation='relu',\n",
        "        kernel_initializer='VarianceScaling',\n",
        "        kernel_regularizer=keras.regularizers.l2(0.001)\n",
        "    ))\n",
        "    \n",
        "    model.add(keras.layers.MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    ))\n",
        "    \n",
        "    model.add(keras.layers.Dropout(0.05))\n",
        "    \n",
        "    # Now we flatten the output from the 2D filters into a 1D vector to prepare\n",
        "    # it for input into our last layer. This is common practice when feeding\n",
        "    # higher dimensional data to a final classification output layer.\n",
        "    model.add(keras.layers.Flatten())\n",
        "    \n",
        "    \n",
        "    # Our last layer is a dense layer which has 10 output units, one for each\n",
        "    # output class (i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9).\n",
        "    NUM_OUTPUT_CLASSES = 10;\n",
        "    model.add(keras.layers.Dense(\n",
        "        units=NUM_OUTPUT_CLASSES,\n",
        "        activation='softmax',\n",
        "        kernel_initializer='VarianceScaling',\n",
        "        kernel_regularizer=keras.regularizers.l2(0.001)\n",
        "    ))\n",
        "    \n",
        "    \n",
        "    # Choose an optimizer, loss function and accuracy matric,\n",
        "    # then compile and return the model\n",
        "    optimizer = keras.optimizers.Adam();\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQxPleS6PLXf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "?? keras.callbacks.History"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EAaB2Hxf495N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "pBn_KbQXFbn6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Selection"
      ]
    },
    {
      "metadata": {
        "id": "NrvHkr1cFt31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### K-Fold"
      ]
    },
    {
      "metadata": {
        "id": "DrMF8vYtnKGb",
        "colab_type": "code",
        "outputId": "7da4525f-62d0-415d-88b3-6788bc2b880f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 60000\n",
        "NUM_TEST_SAMPLES = 10000\n",
        "\n",
        "K_FOLD = 3\n",
        "NUM_VALIDATION_SAMPLES = NUM_TRAIN_SAMPLES // K_FOLD\n",
        "\n",
        "train, test = mnist.load_data()\n",
        "\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "shuffled_indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "x_train = x_train[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]\n",
        "\n",
        "x_train = x_train.reshape((NUM_TRAIN_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.reshape((NUM_TEST_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "validation_scores = []\n",
        "\n",
        "for fold in range(K_FOLD):\n",
        "  x_val = x_train[NUM_VALIDATION_SAMPLES * fold: NUM_VALIDATION_SAMPLES * (fold+1)]\n",
        "  y_val = y_train[NUM_VALIDATION_SAMPLES * fold: NUM_VALIDATION_SAMPLES * (fold+1)]\n",
        "  \n",
        "  x_train_fld = np.concatenate((x_train[:NUM_VALIDATION_SAMPLES * fold], x_train[NUM_VALIDATION_SAMPLES * (fold+1):]))\n",
        "  y_train_fld = np.concatenate((y_train[:NUM_VALIDATION_SAMPLES * fold], y_train[NUM_VALIDATION_SAMPLES * (fold+1):]))\n",
        "  \n",
        "  model = get_model()\n",
        "  model.fit(\n",
        "      x_train_fld,\n",
        "      y_train_fld,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      epochs=NUM_EPOCHS,\n",
        "      shuffle=True,\n",
        "      callbacks=None\n",
        "  )\n",
        "  scores = model.evaluate(x_val, y_val)\n",
        "  validation_scores.append(scores)\n",
        "  \n",
        "np.average(validation_scores, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "\r    8192/11490434 [..............................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 15s 381us/sample - loss: 3.4864 - accuracy: 0.2545\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 15s 384us/sample - loss: 1.4433 - accuracy: 0.5096\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 15s 383us/sample - loss: 0.5813 - accuracy: 0.8330\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 17s 430us/sample - loss: 0.4094 - accuracy: 0.8850\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 15s 379us/sample - loss: 0.3393 - accuracy: 0.9063\n",
            "20000/20000 [==============================] - 3s 138us/sample - loss: 0.2571 - accuracy: 0.9330\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 15s 385us/sample - loss: 3.1276 - accuracy: 0.3072\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 15s 385us/sample - loss: 0.8583 - accuracy: 0.7247\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 15s 381us/sample - loss: 0.4600 - accuracy: 0.8654\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 17s 434us/sample - loss: 0.3439 - accuracy: 0.9032\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 16s 394us/sample - loss: 0.2721 - accuracy: 0.9258\n",
            "20000/20000 [==============================] - 4s 183us/sample - loss: 0.1954 - accuracy: 0.9491\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 16s 391us/sample - loss: 3.6697 - accuracy: 0.2382\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 15s 380us/sample - loss: 1.3219 - accuracy: 0.5789\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 16s 402us/sample - loss: 0.5811 - accuracy: 0.8270\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 16s 406us/sample - loss: 0.3741 - accuracy: 0.8942\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 15s 376us/sample - loss: 0.2685 - accuracy: 0.9273\n",
            "20000/20000 [==============================] - 3s 138us/sample - loss: 0.1964 - accuracy: 0.9484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.21627314, 0.94350002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "FxH_f5ZhF0AX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Epoch selection"
      ]
    },
    {
      "metadata": {
        "id": "Es-T0Zs4Fya9",
        "colab_type": "code",
        "outputId": "d9fabc9b-c25b-402c-c815-39b6788774f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 60000\n",
        "NUM_TEST_SAMPLES = 10000\n",
        "\n",
        "NUM_VALIDATION_SAMPLES = NUM_TRAIN_SAMPLES * 10 // 100 # 10% of training samples\n",
        "\n",
        "MAX_EPOCHS = 20\n",
        "\n",
        "train, test = mnist.load_data()\n",
        "\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "shuffled_indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "x_train = x_train[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]\n",
        "\n",
        "x_train = x_train.reshape((NUM_TRAIN_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.reshape((NUM_TEST_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "validation_scores = []\n",
        "\n",
        "\n",
        "x_val = x_train[:NUM_VALIDATION_SAMPLES]\n",
        "y_val = y_train[:NUM_VALIDATION_SAMPLES]\n",
        "\n",
        "x_train_ = x_train[NUM_VALIDATION_SAMPLES:]\n",
        "y_train_ = y_train[NUM_VALIDATION_SAMPLES:]\n",
        "\n",
        "model = get_model()\n",
        "history = model.fit(\n",
        "    x_train_,\n",
        "    y_train_,\n",
        "    validation_data=(x_val, y_val),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=MAX_EPOCHS,\n",
        "    shuffle=True,\n",
        "    callbacks=None\n",
        ")\n",
        "\n",
        "  "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/20\n",
            "54000/54000 [==============================] - 24s 443us/sample - loss: 0.4287 - accuracy: 0.8788 - val_loss: 0.1881 - val_accuracy: 0.9563\n",
            "Epoch 2/20\n",
            "54000/54000 [==============================] - 22s 412us/sample - loss: 0.1833 - accuracy: 0.9599 - val_loss: 0.1564 - val_accuracy: 0.9697\n",
            "Epoch 3/20\n",
            "54000/54000 [==============================] - 25s 457us/sample - loss: 0.1578 - accuracy: 0.9685 - val_loss: 0.1539 - val_accuracy: 0.9683\n",
            "Epoch 4/20\n",
            "54000/54000 [==============================] - 22s 409us/sample - loss: 0.1427 - accuracy: 0.9721 - val_loss: 0.1350 - val_accuracy: 0.9737\n",
            "Epoch 5/20\n",
            "54000/54000 [==============================] - 22s 413us/sample - loss: 0.1348 - accuracy: 0.9748 - val_loss: 0.1332 - val_accuracy: 0.9763\n",
            "Epoch 6/20\n",
            "54000/54000 [==============================] - 22s 413us/sample - loss: 0.1279 - accuracy: 0.9766 - val_loss: 0.1208 - val_accuracy: 0.9797\n",
            "Epoch 7/20\n",
            "54000/54000 [==============================] - 24s 452us/sample - loss: 0.1248 - accuracy: 0.9773 - val_loss: 0.1193 - val_accuracy: 0.9808\n",
            "Epoch 8/20\n",
            "54000/54000 [==============================] - 22s 405us/sample - loss: 0.1219 - accuracy: 0.9784 - val_loss: 0.1175 - val_accuracy: 0.9785\n",
            "Epoch 9/20\n",
            "54000/54000 [==============================] - 22s 411us/sample - loss: 0.1198 - accuracy: 0.9790 - val_loss: 0.1113 - val_accuracy: 0.9817\n",
            "Epoch 10/20\n",
            "54000/54000 [==============================] - 24s 440us/sample - loss: 0.1190 - accuracy: 0.9794 - val_loss: 0.1117 - val_accuracy: 0.9815\n",
            "Epoch 11/20\n",
            "54000/54000 [==============================] - 22s 407us/sample - loss: 0.1144 - accuracy: 0.9808 - val_loss: 0.1184 - val_accuracy: 0.9802\n",
            "Epoch 12/20\n",
            "54000/54000 [==============================] - 22s 402us/sample - loss: 0.1135 - accuracy: 0.9805 - val_loss: 0.1143 - val_accuracy: 0.9805\n",
            "Epoch 13/20\n",
            "54000/54000 [==============================] - 22s 407us/sample - loss: 0.1132 - accuracy: 0.9813 - val_loss: 0.1121 - val_accuracy: 0.9813\n",
            "Epoch 14/20\n",
            "54000/54000 [==============================] - 26s 479us/sample - loss: 0.1118 - accuracy: 0.9820 - val_loss: 0.1100 - val_accuracy: 0.9818\n",
            "Epoch 15/20\n",
            "54000/54000 [==============================] - 22s 407us/sample - loss: 0.1112 - accuracy: 0.9815 - val_loss: 0.1077 - val_accuracy: 0.9840\n",
            "Epoch 16/20\n",
            "54000/54000 [==============================] - 22s 409us/sample - loss: 0.1097 - accuracy: 0.9822 - val_loss: 0.1085 - val_accuracy: 0.9828\n",
            "Epoch 17/20\n",
            "54000/54000 [==============================] - 24s 442us/sample - loss: 0.1093 - accuracy: 0.9825 - val_loss: 0.1077 - val_accuracy: 0.9830\n",
            "Epoch 18/20\n",
            "54000/54000 [==============================] - 22s 412us/sample - loss: 0.1078 - accuracy: 0.9832 - val_loss: 0.1078 - val_accuracy: 0.9830\n",
            "Epoch 19/20\n",
            "54000/54000 [==============================] - 22s 405us/sample - loss: 0.1082 - accuracy: 0.9830 - val_loss: 0.1073 - val_accuracy: 0.9818\n",
            "Epoch 20/20\n",
            "54000/54000 [==============================] - 22s 400us/sample - loss: 0.1084 - accuracy: 0.9827 - val_loss: 0.1045 - val_accuracy: 0.9842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6NPlnYMcTwJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"cpt-2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4j0icVgGP0Is",
        "colab_type": "code",
        "outputId": "cb165c0a-15ec-4258-c7e1-f130b2b90c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "history_copy = history.history.copy()\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_,\n",
        "    y_train_,\n",
        "    validation_data=(x_val, y_val),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=MAX_EPOCHS,\n",
        "    shuffle=True,\n",
        "    callbacks=None\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "54000/54000 [==============================] - 20s 378us/sample - loss: 0.1040 - accuracy: 0.9736 - val_loss: 0.0822 - val_accuracy: 0.9812\n",
            "Epoch 2/10\n",
            "54000/54000 [==============================] - 22s 414us/sample - loss: 0.0965 - accuracy: 0.9755 - val_loss: 0.0816 - val_accuracy: 0.9798\n",
            "Epoch 3/10\n",
            "54000/54000 [==============================] - 20s 375us/sample - loss: 0.0908 - accuracy: 0.9776 - val_loss: 0.0608 - val_accuracy: 0.9850\n",
            "Epoch 4/10\n",
            "54000/54000 [==============================] - 20s 374us/sample - loss: 0.0883 - accuracy: 0.9782 - val_loss: 0.0700 - val_accuracy: 0.9832\n",
            "Epoch 5/10\n",
            "54000/54000 [==============================] - 21s 388us/sample - loss: 0.0825 - accuracy: 0.9803 - val_loss: 0.0682 - val_accuracy: 0.9833\n",
            "Epoch 6/10\n",
            "54000/54000 [==============================] - 24s 442us/sample - loss: 0.0783 - accuracy: 0.9803 - val_loss: 0.0644 - val_accuracy: 0.9835\n",
            "Epoch 7/10\n",
            "54000/54000 [==============================] - 20s 377us/sample - loss: 0.0771 - accuracy: 0.9815 - val_loss: 0.0730 - val_accuracy: 0.9828\n",
            "Epoch 8/10\n",
            "54000/54000 [==============================] - 20s 379us/sample - loss: 0.0724 - accuracy: 0.9829 - val_loss: 0.0664 - val_accuracy: 0.9840\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 22s 413us/sample - loss: 0.0757 - accuracy: 0.9814 - val_loss: 0.0677 - val_accuracy: 0.9840\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 20s 379us/sample - loss: 0.0694 - accuracy: 0.9842 - val_loss: 0.0689 - val_accuracy: 0.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x5i_RnUYOeGJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plot the epoch wise performance"
      ]
    },
    {
      "metadata": {
        "id": "GGAloTsIOHnq",
        "colab_type": "code",
        "outputId": "01a864ba-30f5-4e12-9d0b-c14cbe50796a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJNb/By1eAoYTzsuAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oydEwhpunsdi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate on test set"
      ]
    },
    {
      "metadata": {
        "id": "-h_RNkSnnsJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a8b63a9-39f3-4969-a96e-0b83d9d01710"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 179us/sample - loss: 0.0913 - accuracy: 0.9871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09131579405069351, 0.9871]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "PySkMmLIn6X6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0d9b34e-9d4b-48af-a0b6-33bbc30fcebb"
      },
      "cell_type": "code",
      "source": [
        "x_test.dtype"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "50JLVFzAC_lg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the following code to authenticate/authorize your Google Drive for the purpose of mounting in this virtual machine\n",
        "### we will use this to save the trained model to your GDrive"
      ]
    },
    {
      "metadata": {
        "id": "ftHask3MBwdI",
        "colab_type": "code",
        "outputId": "5645e728-50a0-4dae-82e3-cc5778a7992f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Run this to authenticate/authorize your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LLx_2gZiDQI9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the model"
      ]
    },
    {
      "metadata": {
        "id": "Ii62I4m-jiFH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_PATH_GDRIVE = '/content/gdrive/My Drive/mnist_cnn_tfjs'\n",
        "tfjs.converters.save_keras_model(model, MODEL_SAVE_PATH_GDRIVE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBS1CRtsDSGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The trained model is now available in your Google Drive in the location `My Drive/mnist_cnn_tfjs`"
      ]
    }
  ]
}