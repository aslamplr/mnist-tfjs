{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Model_for_web.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wwA8UssSmJuE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST Handwritten digit classifier in browser\n",
        "\n",
        "This notebook creates, train and export a model trained in MNIST handwritten digit classifying task, to be imported by tfjs in browser.\n"
      ]
    },
    {
      "metadata": {
        "id": "BsJ7LGe-mmoS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "install `tensorflowjs`, which is only required in this notebook for saving the model compatible with `tensorflowjs`"
      ]
    },
    {
      "metadata": {
        "id": "855JDkg9jBMa",
        "colab_type": "code",
        "outputId": "3bbd8e5f-2662-4f95-a177-b436c974f284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1211
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/79/29/35e1aa467436ff46b98df65a08c49faaedb3429e1c512d1d90fe308040a0/tensorflowjs-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting six==1.11.0 (from tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
            "Collecting tensorflow-hub==0.3.0 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/f0/3a3ced04c8359e562f1b91918d9bde797c8a916fcfeddc8dc5d673d1be20/tensorflow_hub-0.3.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 7.5MB/s \n",
            "\u001b[?25hCollecting tf-nightly-2.0-preview>=2.0.0.dev20190304 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/43/0fd24debfa52b8485b078fc7d10a5b760ab61e6975d2e36cb3269a6051b2/tf_nightly_2.0_preview-2.0.0.dev20190427-cp36-cp36m-manylinux1_x86_64.whl (87.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 87.1MB 590kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.4)\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.3.0->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.7)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/65/b063305deef778891c2a43f93f2ed38445e121c9496aa5f99b9be46acc7c/tensorflow_estimator_2.0_preview-1.14.0.dev2019042700-py2.py3-none-any.whl (426kB)\n",
            "\u001b[K    100% |████████████████████████████████| 430kB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.33.1)\n",
            "Collecting wrapt>=1.11.1 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.2.2)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/bb/f1bbc131d6294baa6085a222d29abadd012696b73dcbf8cf1bf56b9f082a/google_pasta-0.1.5-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 27.2MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/c6/e699c210a72660744a36e7f24b4a5a2bf798ce27d009a7f48050a620569f/tb_nightly-1.14.0a20190427-py3-none-any.whl (3.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.0.9)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.3.0->tensorflowjs) (40.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.15.2)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
            "Successfully built wrapt\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31ms3fs 0.2.1 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, numpy, tensorflow-hub, tensorflow-estimator-2.0-preview, wrapt, google-pasta, tb-nightly, tf-nightly-2.0-preview, tensorflowjs\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: numpy 1.16.3\n",
            "    Uninstalling numpy-1.16.3:\n",
            "      Successfully uninstalled numpy-1.16.3\n",
            "  Found existing installation: tensorflow-hub 0.4.0\n",
            "    Uninstalling tensorflow-hub-0.4.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.4.0\n",
            "  Found existing installation: wrapt 1.10.11\n",
            "    Uninstalling wrapt-1.10.11:\n",
            "      Successfully uninstalled wrapt-1.10.11\n",
            "Successfully installed google-pasta-0.1.5 numpy-1.15.1 six-1.11.0 tb-nightly-1.14.0a20190427 tensorflow-estimator-2.0-preview-1.14.0.dev2019042700 tensorflow-hub-0.3.0 tensorflowjs-1.0.1 tf-nightly-2.0-preview-2.0.0.dev20190427 wrapt-1.11.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rjf9ZYItm2Yx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Packages required for the notebook"
      ]
    },
    {
      "metadata": {
        "id": "twu1gnJ0h8_G",
        "colab_type": "code",
        "outputId": "1584f9e9-b337-4e9f-8ec6-f1a177ca807a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs\n",
        "from tensorflow import keras\n",
        "\n",
        "print('tensorflow', tf.__version__)\n",
        "print('tensorflowjs', tfjs.__version__)\n",
        "print('keras', keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow 2.0.0-dev20190427\n",
            "tensorflowjs 1.0.1\n",
            "keras 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aZeVYmBiMEn0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While this notebook was written the versions used were - \n",
        "```\n",
        "tensorflow 2.0.0-dev20190412\n",
        "tensorflowjs 1.0.1\n",
        "keras 2.2.4-tf\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "ZeTyjXn0ny-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Constants"
      ]
    },
    {
      "metadata": {
        "id": "DkSnKIQNnyVj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGE_WIDTH = 28\n",
        "IMAGE_HEIGHT = 28\n",
        "IMAGE_CHANNELS = 1\n",
        "\n",
        "NUM_EPOCHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15udzoCYnMDd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The model\n",
        "\n",
        "Let's create the model"
      ]
    },
    {
      "metadata": {
        "id": "ktSJlZx2nh4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    model = keras.Sequential()\n",
        "    \n",
        "    # In the first layer of out convolutional neural network we have\n",
        "    # to specify the input shape. Then we specify some paramaters for\n",
        "    # the convolution operation that takes place in this layer.\n",
        "    model.add(keras.layers.Conv2D(\n",
        "        input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS),\n",
        "        kernel_size=3,\n",
        "        filters=32,\n",
        "        strides=1,\n",
        "        activation='relu',\n",
        "        kernel_initializer='VarianceScaling'\n",
        "    ))\n",
        "    \n",
        "    # The MaxPooling layer acts as a sort of downsampling using max values\n",
        "    # in a region instead of averaging.\n",
        "    model.add(keras.layers.MaxPool2D(\n",
        "        pool_size=(2,2), \n",
        "        strides=(2,2)\n",
        "    ))\n",
        "    \n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    \n",
        "    # Repeat another Conv2D + MazPooling stack.\n",
        "    # Note that we have more filters in the convolution.\n",
        "    model.add(keras.layers.Conv2D(\n",
        "        kernel_size=3,\n",
        "        filters=64,\n",
        "        strides=1,\n",
        "        activation='relu',\n",
        "        kernel_initializer='VarianceScaling'\n",
        "    ))\n",
        "    \n",
        "    model.add(keras.layers.MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    ))\n",
        "    \n",
        "    model.add(keras.layers.Conv2D(\n",
        "        kernel_size=3,\n",
        "        filters=64,\n",
        "        strides=1,\n",
        "        activation='relu',\n",
        "        kernel_initializer='VarianceScaling'\n",
        "    ))\n",
        "    \n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    \n",
        "    # Now we flatten the output from the 2D filters into a 1D vector to prepare\n",
        "    # it for input into our last layer. This is common practice when feeding\n",
        "    # higher dimensional data to a final classification output layer.\n",
        "    model.add(keras.layers.Flatten())\n",
        "    \n",
        "    model.add(keras.layers.Dense(\n",
        "        units=64,\n",
        "        activation='relu',\n",
        "        kernel_initializer='VarianceScaling',\n",
        "        kernel_regularizer=keras.regularizers.l2(0.001)\n",
        "    ))\n",
        "    \n",
        "    # Our last layer is a dense layer which has 10 output units, one for each\n",
        "    # output class (i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9).\n",
        "    NUM_OUTPUT_CLASSES = 10;\n",
        "    model.add(keras.layers.Dense(\n",
        "        units=NUM_OUTPUT_CLASSES,\n",
        "        activation='softmax',\n",
        "        kernel_initializer='VarianceScaling',\n",
        "        kernel_regularizer=keras.regularizers.l2(0.001)\n",
        "    ))\n",
        "    \n",
        "    \n",
        "    # Choose an optimizer, loss function and accuracy matric,\n",
        "    # then compile and return the model\n",
        "    optimizer = keras.optimizers.Adam();\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQxPleS6PLXf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "?? keras.layers.Conv2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EAaB2Hxf495N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "pBn_KbQXFbn6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Selection"
      ]
    },
    {
      "metadata": {
        "id": "NrvHkr1cFt31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### K-Fold"
      ]
    },
    {
      "metadata": {
        "id": "DrMF8vYtnKGb",
        "colab_type": "code",
        "outputId": "7da4525f-62d0-415d-88b3-6788bc2b880f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 60000\n",
        "NUM_TEST_SAMPLES = 10000\n",
        "\n",
        "K_FOLD = 3\n",
        "NUM_VALIDATION_SAMPLES = NUM_TRAIN_SAMPLES // K_FOLD\n",
        "\n",
        "train, test = mnist.load_data()\n",
        "\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "shuffled_indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "x_train = x_train[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]\n",
        "\n",
        "x_train = x_train.reshape((NUM_TRAIN_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.reshape((NUM_TEST_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "validation_scores = []\n",
        "\n",
        "for fold in range(K_FOLD):\n",
        "  x_val = x_train[NUM_VALIDATION_SAMPLES * fold: NUM_VALIDATION_SAMPLES * (fold+1)]\n",
        "  y_val = y_train[NUM_VALIDATION_SAMPLES * fold: NUM_VALIDATION_SAMPLES * (fold+1)]\n",
        "  \n",
        "  x_train_fld = np.concatenate((x_train[:NUM_VALIDATION_SAMPLES * fold], x_train[NUM_VALIDATION_SAMPLES * (fold+1):]))\n",
        "  y_train_fld = np.concatenate((y_train[:NUM_VALIDATION_SAMPLES * fold], y_train[NUM_VALIDATION_SAMPLES * (fold+1):]))\n",
        "  \n",
        "  model = get_model()\n",
        "  model.fit(\n",
        "      x_train_fld,\n",
        "      y_train_fld,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      epochs=NUM_EPOCHS,\n",
        "      shuffle=True,\n",
        "      callbacks=None\n",
        "  )\n",
        "  scores = model.evaluate(x_val, y_val)\n",
        "  validation_scores.append(scores)\n",
        "  \n",
        "np.average(validation_scores, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "\r    8192/11490434 [..............................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 15s 381us/sample - loss: 3.4864 - accuracy: 0.2545\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 15s 384us/sample - loss: 1.4433 - accuracy: 0.5096\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 15s 383us/sample - loss: 0.5813 - accuracy: 0.8330\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 17s 430us/sample - loss: 0.4094 - accuracy: 0.8850\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 15s 379us/sample - loss: 0.3393 - accuracy: 0.9063\n",
            "20000/20000 [==============================] - 3s 138us/sample - loss: 0.2571 - accuracy: 0.9330\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 15s 385us/sample - loss: 3.1276 - accuracy: 0.3072\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 15s 385us/sample - loss: 0.8583 - accuracy: 0.7247\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 15s 381us/sample - loss: 0.4600 - accuracy: 0.8654\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 17s 434us/sample - loss: 0.3439 - accuracy: 0.9032\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 16s 394us/sample - loss: 0.2721 - accuracy: 0.9258\n",
            "20000/20000 [==============================] - 4s 183us/sample - loss: 0.1954 - accuracy: 0.9491\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 16s 391us/sample - loss: 3.6697 - accuracy: 0.2382\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 15s 380us/sample - loss: 1.3219 - accuracy: 0.5789\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 16s 402us/sample - loss: 0.5811 - accuracy: 0.8270\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 16s 406us/sample - loss: 0.3741 - accuracy: 0.8942\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 15s 376us/sample - loss: 0.2685 - accuracy: 0.9273\n",
            "20000/20000 [==============================] - 3s 138us/sample - loss: 0.1964 - accuracy: 0.9484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.21627314, 0.94350002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "FxH_f5ZhF0AX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Epoch selection"
      ]
    },
    {
      "metadata": {
        "id": "Es-T0Zs4Fya9",
        "colab_type": "code",
        "outputId": "f91f4692-0f35-41fc-83ae-ed59e17ef7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 60000\n",
        "NUM_TEST_SAMPLES = 10000\n",
        "\n",
        "NUM_VALIDATION_SAMPLES = NUM_TRAIN_SAMPLES * 10 // 100 # 10% of training samples\n",
        "\n",
        "MAX_EPOCHS = 10\n",
        "\n",
        "train, test = mnist.load_data()\n",
        "\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "shuffled_indices = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "x_train = x_train[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]\n",
        "\n",
        "x_train = x_train.reshape((NUM_TRAIN_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.reshape((NUM_TEST_SAMPLES, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "validation_scores = []\n",
        "\n",
        "\n",
        "x_val = x_train[:NUM_VALIDATION_SAMPLES]\n",
        "y_val = y_train[:NUM_VALIDATION_SAMPLES]\n",
        "\n",
        "x_train_ = x_train[NUM_VALIDATION_SAMPLES:]\n",
        "y_train_ = y_train[NUM_VALIDATION_SAMPLES:]\n",
        "\n",
        "model = get_model()\n",
        "history = model.fit(\n",
        "    x_train_,\n",
        "    y_train_,\n",
        "    validation_data=(x_val, y_val),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=MAX_EPOCHS,\n",
        "    shuffle=True,\n",
        "    callbacks=None\n",
        ")\n",
        "\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "54000/54000 [==============================] - 40s 742us/sample - loss: 0.2666 - accuracy: 0.9339 - val_loss: 0.1131 - val_accuracy: 0.9790\n",
            "Epoch 2/10\n",
            "54000/54000 [==============================] - 41s 758us/sample - loss: 0.1110 - accuracy: 0.9790 - val_loss: 0.0775 - val_accuracy: 0.9858\n",
            "Epoch 3/10\n",
            "54000/54000 [==============================] - 41s 757us/sample - loss: 0.0896 - accuracy: 0.9832 - val_loss: 0.0738 - val_accuracy: 0.9873\n",
            "Epoch 4/10\n",
            "54000/54000 [==============================] - 40s 750us/sample - loss: 0.0757 - accuracy: 0.9860 - val_loss: 0.0612 - val_accuracy: 0.9902\n",
            "Epoch 5/10\n",
            "54000/54000 [==============================] - 39s 717us/sample - loss: 0.0689 - accuracy: 0.9874 - val_loss: 0.0659 - val_accuracy: 0.9882\n",
            "Epoch 6/10\n",
            "54000/54000 [==============================] - 40s 746us/sample - loss: 0.0625 - accuracy: 0.9883 - val_loss: 0.0594 - val_accuracy: 0.9887\n",
            "Epoch 7/10\n",
            "54000/54000 [==============================] - 39s 715us/sample - loss: 0.0598 - accuracy: 0.9889 - val_loss: 0.0600 - val_accuracy: 0.9895\n",
            "Epoch 8/10\n",
            "54000/54000 [==============================] - 40s 748us/sample - loss: 0.0545 - accuracy: 0.9895 - val_loss: 0.0486 - val_accuracy: 0.9915\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 38s 706us/sample - loss: 0.0528 - accuracy: 0.9903 - val_loss: 0.0515 - val_accuracy: 0.9903\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 40s 744us/sample - loss: 0.0487 - accuracy: 0.9915 - val_loss: 0.0443 - val_accuracy: 0.9932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6NPlnYMcTwJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"cpt-5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4j0icVgGP0Is",
        "colab_type": "code",
        "outputId": "b924b756-6e6f-4f0a-8ada-88607d1804c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "history_copy = history.history.copy()\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_,\n",
        "    y_train_,\n",
        "    validation_data=(x_val, y_val),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=MAX_EPOCHS,\n",
        "    shuffle=True,\n",
        "    callbacks=None\n",
        ")\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/5\n",
            "54000/54000 [==============================] - 41s 763us/sample - loss: 0.1405 - accuracy: 0.9835 - val_loss: 0.1409 - val_accuracy: 0.9832\n",
            "Epoch 2/5\n",
            "54000/54000 [==============================] - 39s 720us/sample - loss: 0.1407 - accuracy: 0.9840 - val_loss: 0.1426 - val_accuracy: 0.9828\n",
            "Epoch 3/5\n",
            "54000/54000 [==============================] - 42s 774us/sample - loss: 0.1389 - accuracy: 0.9837 - val_loss: 0.1341 - val_accuracy: 0.9857\n",
            "Epoch 4/5\n",
            "54000/54000 [==============================] - 38s 703us/sample - loss: 0.1375 - accuracy: 0.9839 - val_loss: 0.1327 - val_accuracy: 0.9860\n",
            "Epoch 5/5\n",
            "54000/54000 [==============================] - 40s 742us/sample - loss: 0.1368 - accuracy: 0.9844 - val_loss: 0.1363 - val_accuracy: 0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x5i_RnUYOeGJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plot the epoch wise performance"
      ]
    },
    {
      "metadata": {
        "id": "GGAloTsIOHnq",
        "colab_type": "code",
        "outputId": "9016785c-3de6-44bf-afce-6b46562af9fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oydEwhpunsdi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate on test set"
      ]
    },
    {
      "metadata": {
        "id": "-h_RNkSnnsJF",
        "colab_type": "code",
        "outputId": "761edcfa-9663-4a31-a729-8ee44b387a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 219us/sample - loss: 0.0433 - accuracy: 0.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.043273243573307994, 0.9929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "PySkMmLIn6X6",
        "colab_type": "code",
        "outputId": "f0d9b34e-9d4b-48af-a0b6-33bbc30fcebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_test.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "50JLVFzAC_lg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Run the following code to authenticate/authorize your Google Drive for the purpose of mounting in this virtual machine\n",
        "### we will use this to save the trained model to your GDrive"
      ]
    },
    {
      "metadata": {
        "id": "ftHask3MBwdI",
        "colab_type": "code",
        "outputId": "d39e18aa-9dfe-4e34-91bf-914965f8e99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "cell_type": "code",
      "source": [
        "# Run this to authenticate/authorize your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LLx_2gZiDQI9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the model"
      ]
    },
    {
      "metadata": {
        "id": "Ii62I4m-jiFH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_PATH_GDRIVE = '/content/gdrive/My Drive/mnist_cnn_tfjs'\n",
        "tfjs.converters.save_keras_model(model, MODEL_SAVE_PATH_GDRIVE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBS1CRtsDSGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The trained model is now available in your Google Drive in the location `My Drive/mnist_cnn_tfjs`"
      ]
    }
  ]
}